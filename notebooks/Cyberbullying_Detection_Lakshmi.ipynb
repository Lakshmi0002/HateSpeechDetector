{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce1b6d5-8009-4892-8e24-d4f25c0132a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be4f856c-0272-4141-8874-075140487e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('output1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe51a7c0-3e4d-4964-bfbf-ad11c5fc5e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>I dont. But what is complaining about it goi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Bahah  yeah i&amp;;m totally just gonna&amp;; get pis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>hahahahaha &gt;:) im evil mwahahahahahahahahaha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>What&amp;;s something unique about Ohio? :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>Who is the biggest gossiper you know?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20001 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  annotation_label\n",
       "0                                 Get fucking real dude.                 1\n",
       "1       She is as dirty as they come  and that crook ...                 1\n",
       "2       why did you fuck it up. I could do it all day...                 1\n",
       "3       Dude they dont finish enclosing the fucking s...                 1\n",
       "4       WTF are you talking about Men? No men thats n...                 1\n",
       "...                                                  ...               ...\n",
       "19996    I dont. But what is complaining about it goi...                 0\n",
       "19997   Bahah  yeah i&;m totally just gonna&; get pis...                 0\n",
       "19998       hahahahaha >:) im evil mwahahahahahahahahaha                 0\n",
       "19999            What&;s something unique about Ohio? :)                 0\n",
       "20000              Who is the biggest gossiper you know?                 0\n",
       "\n",
       "[20001 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e0eadb-36ab-423d-b464-0b06311ccf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename target column \n",
    "data.rename(columns={'annotation_label': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b2da005-3578-4e9d-b2cf-d4b63181869f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0                             Get fucking real dude.      1\n",
       "1   She is as dirty as they come  and that crook ...      1\n",
       "2   why did you fuck it up. I could do it all day...      1\n",
       "3   Dude they dont finish enclosing the fucking s...      1\n",
       "4   WTF are you talking about Men? No men thats n...      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7093a546-e794-45df-961f-0a1a4ffc2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(data['content'], data['label'],test_size=0.2, random_state=42, stratify=data['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d1f643f-3178-4cde-a01f-1a644c18d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load HateBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"GroNLP/hateBERT\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "415aefdb-374e-42c9-a8a1-466617025127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(list(texts), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = tokenize_function(x_train)\n",
    "val_encodings = tokenize_function(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec3934d5-c18c-4b1e-a0de-73716243b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return dictionary with keys 'input_ids', 'attention_mask', and 'labels'\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97f76d77-3161-4aa7-998a-2a723b445666",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_encodings, y_train.tolist())\n",
    "val_dataset = Dataset(val_encodings, y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0dac8e5b-db9a-49b1-a2ef-cf2b9c81c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b9af78e-462e-40aa-98b8-99e8d512f463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6000/6000 25:44:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.513200</td>\n",
       "      <td>0.392384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.476358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.562276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6000, training_loss=0.28868438343781355, metrics={'train_runtime': 92758.0488, 'train_samples_per_second': 0.517, 'train_steps_per_second': 0.065, 'total_flos': 6487331958720000.0, 'train_loss': 0.28868438343781355, 'epoch': 3.0})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8c49f0f-4dd6-4c25-bca5-c8ce399b0cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = trainer.predict(val_dataset)\n",
    "predicted_labels = predictions.predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9fd26325-c41c-4660-b9ef-48534b0048c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Bullying       0.87      0.84      0.85      2436\n",
      "    Bullying       0.76      0.81      0.78      1565\n",
      "\n",
      "    accuracy                           0.83      4001\n",
      "   macro avg       0.82      0.82      0.82      4001\n",
      "weighted avg       0.83      0.83      0.83      4001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, predicted_labels, target_names=[\"Non-Bullying\", \"Bullying\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1062554-8ead-428f-82c5-83ce3045db75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_hatebert\\\\tokenizer_config.json',\n",
       " './fine_tuned_hatebert\\\\special_tokens_map.json',\n",
       " './fine_tuned_hatebert\\\\vocab.txt',\n",
       " './fine_tuned_hatebert\\\\added_tokens.json',\n",
       " './fine_tuned_hatebert\\\\tokenizer.json')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_hatebert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_hatebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f363ace-6750-4b6a-ba4d-7caf82e696db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text to classify (or type 'exit' to quit):  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hi\n",
      "Prediction: Non-Bullying\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text to classify (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "def classify_text(text):\n",
    "    # Load fine-tuned HateBERT\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_hatebert\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"./fine_tuned_hatebert\")\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    # Map prediction to label\n",
    "    label = \"Non-Bullying\" if predicted_class == 0 else \"Bullying\"\n",
    "    return label\n",
    "\n",
    "# Loop for user-defined input\n",
    "while True:\n",
    "    user_input = input(\"Enter a text to classify (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "    prediction = classify_text(user_input)\n",
    "    print(f\"Input: {user_input}\")\n",
    "    print(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ad633-6823-4e0e-a566-85cb1755f2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47ebcb1-21bb-4c0a-969d-fdf96e45f4a8",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "#### \"Towards Safer Social Platforms: A Machine Learning and NLP Approach to Cyberbullying Detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f91d60-88d3-45f0-9c3e-70b9973be88e",
   "metadata": {},
   "source": [
    "#### Abstract:\n",
    "In the today’s digital era everyone is eager to express their thoughts, emotions and \n",
    "on-going happenings in life to the outer world on various social media platforms. \n",
    "Social media is a vulnerable platform which is exposed to possible weakness and \n",
    "threats. Cyberbullying is the serious problem that can harm the mental and physical \n",
    "well-being of people who are using social media on daily basis to share their \n",
    "thoughts.\n",
    "In contrast to traditional bullying, cyberbullying can happen at any moment, making \n",
    "it challenging for victims to avoid its consequences. Studies show that those who are \n",
    "the targets of cyberbullying may experience suicidal thoughts as well as feelings of \n",
    "depression, anxiety, and loneliness. Constant exposure to negative comments and \n",
    "cyberbullying erodes a person's confidence and self-worth, making them question \n",
    "their worth and ability. In addition, Long-term emotional scars result from victims \n",
    "who lose trust and avoid social connections in person as well as virtually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a26d06-5c54-41cc-9b08-c9d10d7b4ad5",
   "metadata": {},
   "source": [
    "#### Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cc1bd6-9487-4804-86a6-b5beff36ca5b",
   "metadata": {},
   "source": [
    "\n",
    "- The data is from different social media platforms like Kaggle, Twitter and YouTube. The data contain text and labeled as bullying or not. The data contains different types of cyber-bullying like hate speech, aggression, insults and toxicity.\n",
    "- The dataset has 20001 items of which 20001 items have been manually labeled.\n",
    "\n",
    "- The labels are divided into following 2 categories:\n",
    "\n",
    "- 1 (Cyber-Aggressive) 0 (Non Cyber-Aggressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f922f-721e-4032-8455-14b227ebd130",
   "metadata": {},
   "source": [
    "##### Data is sourced from kaggle and is in json format\n",
    "- Converting into csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123eeaa-c170-453e-926b-12a4ff9010ec",
   "metadata": {},
   "source": [
    "\n",
    "##### The below code convertes the existing json file to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c148f9e2-dd9a-4f71-bcef-65845fedc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b26bfd72-4df9-4495-8bc1-1d9b603e768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to output1.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# File paths\n",
    "json_file = 'D:/Essentials/RVU/Mini Project/Datasets/Dataset for Detection of Cyber-Trolls.json'  # Path to your input JSON file\n",
    "csv_file = 'output1.csv'   # Path to your output CSV file\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    # Define only the fields you want to keep (excluding 'annotation_notes' and 'extras')\n",
    "    fieldnames = ['content', 'annotation_label']\n",
    "    \n",
    "    # Create DictWriter object\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Open and read the JSON file\n",
    "    with open(json_file, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line.strip())  # Load each line as JSON\n",
    "                annotation = data.get('annotation', {})\n",
    "                \n",
    "                # Write only the required fields ('content' and 'annotation_label')\n",
    "                writer.writerow({\n",
    "                    'content': data.get('content', ''),\n",
    "                    'annotation_label': ','.join(annotation.get('label', []))\n",
    "                })\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "print(f\"Data successfully written to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d2e88-2c09-4ed2-885b-889e99fd319a",
   "metadata": {},
   "source": [
    "#### Reading the file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "793fa532-65ca-4298-888d-4e6d2d2ac48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('output1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41c30734-a545-4c0a-b952-e095986c2ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>I dont. But what is complaining about it goi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Bahah  yeah i&amp;;m totally just gonna&amp;; get pis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>hahahahaha &gt;:) im evil mwahahahahahahahahaha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>What&amp;;s something unique about Ohio? :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>Who is the biggest gossiper you know?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  annotation_label\n",
       "0                                 Get fucking real dude.                 1\n",
       "1       She is as dirty as they come  and that crook ...                 1\n",
       "2       why did you fuck it up. I could do it all day...                 1\n",
       "3       Dude they dont finish enclosing the fucking s...                 1\n",
       "4       WTF are you talking about Men? No men thats n...                 1\n",
       "...                                                  ...               ...\n",
       "19996    I dont. But what is complaining about it goi...                 0\n",
       "19997   Bahah  yeah i&;m totally just gonna&; get pis...                 0\n",
       "19998       hahahahaha >:) im evil mwahahahahahahahahaha                 0\n",
       "19999            What&;s something unique about Ohio? :)                 0\n",
       "20000              Who is the biggest gossiper you know?                 0\n",
       "\n",
       "[20001 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b5e16-00d4-4b80-92bf-9a1f764e2715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
